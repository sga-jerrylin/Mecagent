#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¶è¡Œå¤„ç†æµæ°´çº¿ - ç”Ÿäº§çº§å®ç°
åŒæ—¶å¤„ç†GLBè½¬æ¢ã€PDFè§£æã€AIåˆ†æä¸‰ä¸ªé€šé“
"""

import os
import json
import asyncio
import tempfile
from pathlib import Path
from typing import Dict, List, Optional, Any
from concurrent.futures import ThreadPoolExecutor, as_completed

from processors.file_processor import PDFProcessor, ModelProcessor
from models.vision_model import Qwen3VLModel
from models.assembly_expert import AssemblyExpertModel
from core.dual_channel_parser import DualChannelParser


class ParallelAssemblyPipeline:
    """å¹¶è¡Œè£…é…è¯´æ˜ä¹¦ç”Ÿæˆæµæ°´çº¿"""
    
    def __init__(
        self,
        dashscope_api_key: Optional[str] = None,
        deepseek_api_key: Optional[str] = None,
        progress_reporter = None
    ):
        """
        åˆå§‹åŒ–å¹¶è¡Œå¤„ç†æµæ°´çº¿
        
        Args:
            dashscope_api_key: é˜¿é‡Œäº‘DashScope API Key
            deepseek_api_key: DeepSeek API Key
            progress_reporter: è¿›åº¦æŠ¥å‘Šå™¨å®ä¾‹
        """
        self.pdf_processor = PDFProcessor(dpi=300)
        self.model_processor = ModelProcessor()
        self.dual_parser = DualChannelParser(progress_reporter=progress_reporter)
        self.assembly_expert = AssemblyExpertModel(deepseek_api_key)

        self.progress_reporter = progress_reporter
        self.temp_dir = None
    
    def _report_progress(self, stage: str, progress: int, message: str, data: Dict = None):
        """æŠ¥å‘Šè¿›åº¦"""
        if self.progress_reporter:
            self.progress_reporter.report_progress(stage, progress, message, data)
    
    def _report_parallel(self, parallel_data: Dict):
        """æŠ¥å‘Šå¹¶è¡Œè¿›åº¦"""
        if self.progress_reporter:
            self.progress_reporter.report_parallel(parallel_data)
    
    def _log(self, message: str, level: str = "info"):
        """è®°å½•æ—¥å¿—"""
        print(f"[{level.upper()}] {message}")
        if self.progress_reporter:
            self.progress_reporter.log(message, level)
    
    async def process_files_parallel(
        self,
        pdf_files: List[str],
        model_files: List[str],
        output_dir: str,
        focus_type: str = "general",
        special_requirements: str = "æ— ç‰¹æ®Šè¦æ±‚"
    ) -> Dict:
        """
        å¹¶è¡Œå¤„ç†è¾“å…¥æ–‡ä»¶å¹¶ç”Ÿæˆè£…é…è¯´æ˜ä¹¦
        
        Args:
            pdf_files: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            model_files: 3Dæ¨¡å‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            focus_type: ä¸“ä¸šé‡ç‚¹ç±»å‹
            special_requirements: ç‰¹æ®Šè¦æ±‚
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
            self.temp_dir = tempfile.mkdtemp()
            
            self._log("ğŸš€ å¼€å§‹å¹¶è¡Œå¤„ç†æµæ°´çº¿", "info")
            
            # å¹¶è¡Œå¤„ç†æ•°æ®å®¹å™¨
            parallel_results = {
                "glb": None,
                "pdf": None,
                "vision": None
            }
            
            # å¹¶è¡Œè¿›åº¦å®¹å™¨
            parallel_progress = {
                "glb": {"progress": 0, "message": "å‡†å¤‡ä¸­...", "completed": 0, "total": len(model_files)},
                "pdf": {"progress": 0, "message": "å‡†å¤‡ä¸­...", "bom_items": 0, "dimensions": 0, "requirements": 0},
                "vision": {"progress": 0, "message": "å‡†å¤‡ä¸­...", "results": []}
            }
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œä¸‰ä¸ªä»»åŠ¡
            with ThreadPoolExecutor(max_workers=3) as executor:
                # æäº¤ä¸‰ä¸ªå¹¶è¡Œä»»åŠ¡
                future_glb = executor.submit(
                    self._process_models_with_progress,
                    model_files,
                    output_path,
                    parallel_progress
                )
                
                future_pdf = executor.submit(
                    self._process_pdfs_with_progress,
                    pdf_files,
                    parallel_progress
                )
                
                future_vision = executor.submit(
                    self._analyze_vision_with_progress,
                    pdf_files,
                    parallel_progress
                )
                
                # ç›‘æ§å¹¶è¡Œä»»åŠ¡è¿›åº¦
                futures = {
                    "glb": future_glb,
                    "pdf": future_pdf,
                    "vision": future_vision
                }
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ŒåŒæ—¶æ›´æ–°è¿›åº¦
                while any(not f.done() for f in futures.values()):
                    # å‘é€å¹¶è¡Œè¿›åº¦æ›´æ–°
                    self._report_parallel(parallel_progress)
                    await asyncio.sleep(0.5)  # æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡

                # è·å–ç»“æœå¹¶æ£€æŸ¥é”™è¯¯
                try:
                    parallel_results["glb"] = future_glb.result()
                    if not parallel_results["glb"]:
                        raise Exception("GLBè½¬æ¢å¤±è´¥ï¼šæœªè¿”å›ç»“æœ")
                except Exception as e:
                    error_msg = f"GLBè½¬æ¢å¤±è´¥: {str(e)}"
                    self._log(f"âŒ {error_msg}", "error")
                    raise Exception(error_msg)

                try:
                    parallel_results["pdf"] = future_pdf.result()
                    if not parallel_results["pdf"]:
                        raise Exception("PDFè§£æå¤±è´¥ï¼šæœªè¿”å›ç»“æœ")
                except Exception as e:
                    error_msg = f"PDFè§£æå¤±è´¥: {str(e)}"
                    self._log(f"âŒ {error_msg}", "error")
                    raise Exception(error_msg)

                try:
                    parallel_results["vision"] = future_vision.result()
                    if not parallel_results["vision"]:
                        # âœ… ä¿®å¤: è§†è§‰åˆ†æå¤±è´¥åº”è¯¥ç«‹å³åœæ­¢ï¼Œä¸ç»§ç»­æ‰§è¡Œ
                        error_msg = "è§†è§‰åˆ†ææœªè¿”å›ç»“æœ"
                        self._log(f"âŒ {error_msg}", "error")
                        raise Exception(error_msg)
                except Exception as e:
                    # âœ… ä¿®å¤: è§†è§‰åˆ†æå¤±è´¥åº”è¯¥ç«‹å³åœæ­¢ï¼Œä¸ç»§ç»­æ‰§è¡Œ
                    error_msg = f"è§†è§‰åˆ†æå¤±è´¥: {str(e)}"
                    self._log(f"âŒ {error_msg}", "error")
                    raise Exception(error_msg)

            self._log("âœ… å¹¶è¡Œå¤„ç†å®Œæˆ", "success")

            # ç¬¬äºŒé˜¶æ®µï¼šAIèåˆåˆ†æ
            self._log("ğŸ¤– å¼€å§‹AIèåˆåˆ†æ...", "info")
            self._report_progress("ai", 50, "DeepSeekä¸“å®¶æ¨¡å‹åˆ†æä¸­...")

            print(f"[DEBUG] å‡†å¤‡è°ƒç”¨_generate_assembly_specification")
            print(f"[DEBUG] PDFç»“æœæ•°é‡: {len(parallel_results['pdf'])}")
            print(f"[DEBUG] Visionç»“æœæ•°é‡: {len(parallel_results['vision'])}")
            print(f"[DEBUG] GLBç»“æœæ•°é‡: {len(parallel_results['glb'])}")

            assembly_spec = await self._generate_assembly_specification(
                parallel_results["pdf"],
                parallel_results["vision"],
                parallel_results["glb"],
                focus_type,
                special_requirements
            )

            print(f"[DEBUG] AIèåˆåˆ†æå®Œæˆ")
            self._report_progress("ai", 100, "AIåˆ†æå®Œæˆ")

            # ç¬¬ä¸‰é˜¶æ®µï¼šç”Ÿæˆçˆ†ç‚¸åŠ¨ç”»æ•°æ®
            self._log("ğŸ’¥ ç”ŸæˆGLBçˆ†ç‚¸åŠ¨ç”»æ•°æ®...", "info")
            self._report_progress("explosion", 50, "è®¡ç®—çˆ†ç‚¸å‘é‡...")

            for model_result in parallel_results["glb"]:
                if model_result.get("glb_file") and os.path.exists(model_result["glb_file"]):
                    explosion_result = self.model_processor.generate_explosion_data(
                        glb_path=model_result["glb_file"],
                        assembly_spec=assembly_spec,
                        output_dir=str(output_path)
                    )
                    model_result["explosion_data"] = explosion_result

                    if explosion_result.get("success"):
                        self._log(f"âœ… {model_result['glb_filename']}: {explosion_result['message']}", "success")
                    else:
                        self._log(f"âš ï¸ {model_result['glb_filename']}: {explosion_result.get('message', 'çˆ†ç‚¸æ•°æ®ç”Ÿæˆå¤±è´¥')}", "warning")

            self._report_progress("explosion", 100, "çˆ†ç‚¸åŠ¨ç”»æ•°æ®ç”Ÿæˆå®Œæˆ")
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šç”ŸæˆHTMLè¯´æ˜ä¹¦
            self._log("ğŸ“– ç”ŸæˆHTMLè£…é…è¯´æ˜ä¹¦...", "info")
            self._report_progress("generate", 50, "ç”Ÿæˆäº¤äº’å¼è¯´æ˜ä¹¦...")
            
            html_result = await self._generate_html_manual(
                assembly_spec,
                parallel_results["glb"],
                output_path
            )
            
            self._report_progress("generate", 100, "è¯´æ˜ä¹¦ç”Ÿæˆå®Œæˆ")
            
            # ä¿å­˜å®Œæ•´ç»“æœ
            result = {
                "success": True,
                "pdf_analysis": parallel_results["pdf"],
                "vision_analysis": parallel_results["vision"],
                "model_analysis": parallel_results["glb"],
                "assembly_specification": assembly_spec,
                "html_manual": html_result,
                "output_directory": str(output_path)
            }
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            result_file = output_path / "processing_result.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            self._log(f"âœ… å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_path}", "success")
            return result
            
        except Exception as e:
            self._log(f"âŒ å¤„ç†å¤±è´¥: {str(e)}", "error")
            return {
                "success": False,
                "error": str(e),
                "stage": "parallel_pipeline"
            }
        
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if self.temp_dir and os.path.exists(self.temp_dir):
                import shutil
                shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def _process_models_with_progress(
        self,
        model_files: List[str],
        output_path: Path,
        progress_container: Dict
    ) -> List[Dict]:
        """å¤„ç†3Dæ¨¡å‹æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦æŠ¥å‘Šï¼‰"""
        model_results = []
        models_dir = output_path / "models"
        models_dir.mkdir(exist_ok=True)

        total = len(model_files)

        self._log(f"ğŸ”„ å¼€å§‹STEPâ†’GLBè½¬æ¢ï¼Œå…±{total}ä¸ªæ–‡ä»¶", "info")

        for i, model_file in enumerate(model_files):
            filename = os.path.basename(model_file)

            # æ›´æ–°è¿›åº¦
            progress = int((i / total) * 80)  # è½¬æ¢å 80%
            progress_container["glb"]["progress"] = progress
            progress_container["glb"]["message"] = f"è½¬æ¢ä¸­: {filename}"
            progress_container["glb"]["current_file"] = filename
            progress_container["glb"]["completed"] = i

            self._log(f"ğŸ”„ æ­£åœ¨è½¬æ¢: {filename}", "info")

            # è½¬æ¢ä¸ºGLBæ ¼å¼
            glb_filename = f"model_{i:03d}.glb"
            glb_path = models_dir / glb_filename

            conversion_result = self.model_processor.step_to_glb(
                model_file, str(glb_path)
            )

            if conversion_result["success"]:
                # æ³¨æ„ï¼šfile_processorè¿”å›çš„æ˜¯parts_countï¼Œä¸æ˜¯part_count
                part_count = conversion_result.get("parts_count", 0)
                self._log(f"âœ… {filename} â†’ {glb_filename}: {part_count}ä¸ªé›¶ä»¶", "success")

                model_results.append({
                    "original_file": model_file,
                    "glb_file": str(glb_path),
                    "glb_filename": glb_filename,
                    "conversion": conversion_result,
                    "part_count": part_count,
                    "explosion_data": None  # ç¨åç”Ÿæˆ
                })
            else:
                # âœ… ä¿®å¤: é¿å…error_msgä¸­çš„å¤§æ‹¬å·å¯¼è‡´æ ¼å¼åŒ–é”™è¯¯
                error_msg = conversion_result.get("error", "æœªçŸ¥é”™è¯¯")
                # ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥è€Œä¸æ˜¯f-stringï¼Œé¿å…äºŒæ¬¡æ ¼å¼åŒ–
                log_msg = "âŒ " + filename + " è½¬æ¢å¤±è´¥: " + str(error_msg)
                self._log(log_msg, "error")

                model_results.append({
                    "original_file": model_file,
                    "glb_file": None,
                    "conversion": conversion_result,
                    "explosion_data": None
                })

        # å®Œæˆ
        progress_container["glb"]["progress"] = 100
        progress_container["glb"]["message"] = "GLBè½¬æ¢å®Œæˆ"
        progress_container["glb"]["completed"] = total

        total_parts = sum(m.get("part_count", 0) for m in model_results)
        self._log(f"âœ… STEPâ†’GLBè½¬æ¢å®Œæˆ: {total}ä¸ªæ–‡ä»¶, å…±{total_parts}ä¸ªé›¶ä»¶", "success")

        return model_results
    
    def _process_pdfs_with_progress(
        self,
        pdf_files: List[str],
        progress_container: Dict
    ) -> List[Dict]:
        """å¤„ç†PDFæ–‡ä»¶ï¼ˆå¸¦è¿›åº¦æŠ¥å‘Šï¼‰"""
        pdf_results = []
        total = len(pdf_files)
        
        for i, pdf_file in enumerate(pdf_files):
            # æ›´æ–°è¿›åº¦
            progress = int((i / total) * 100)
            progress_container["pdf"]["progress"] = progress
            progress_container["pdf"]["message"] = f"è§£æä¸­: {os.path.basename(pdf_file)}"
            progress_container["pdf"]["current_file"] = os.path.basename(pdf_file)
            
            # åŒé€šé“è§£æ
            print(f"[DEBUG] å¹¶è¡Œå¤„ç† - å¼€å§‹è§£æPDF: {pdf_file}")
            candidate_facts = self.dual_parser.parse_pdf(pdf_file)
            print(f"[DEBUG] å¹¶è¡Œå¤„ç† - PDFè§£æå®Œæˆ")

            # ç»Ÿè®¡ä¿¡æ¯
            bom_count = len(candidate_facts.get("bom_candidates", []))
            feature_count = len(candidate_facts.get("feature_candidates", []))
            note_count = len(candidate_facts.get("note_candidates", []))

            print(f"[DEBUG] ç»Ÿè®¡: BOM={bom_count}, ç‰¹å¾={feature_count}, å¤‡æ³¨={note_count}")

            progress_container["pdf"]["bom_items"] += bom_count
            progress_container["pdf"]["dimensions"] += feature_count
            progress_container["pdf"]["requirements"] += note_count
            
            pdf_results.append({
                "pdf_file": pdf_file,
                "candidate_facts": candidate_facts,
                "statistics": {
                    "bom_items": bom_count,
                    "features": feature_count,
                    "notes": note_count
                }
            })
        
        # å®Œæˆ
        progress_container["pdf"]["progress"] = 100
        progress_container["pdf"]["message"] = "PDFè§£æå®Œæˆ"

        return pdf_results

    def _analyze_vision_with_progress(
        self,
        pdf_files: List[str],
        progress_container: Dict
    ) -> List[Dict]:
        """è§†è§‰åˆ†æï¼ˆå¸¦è¿›åº¦æŠ¥å‘Šï¼‰"""
        vision_results = []
        total = len(pdf_files)

        for i, pdf_file in enumerate(pdf_files):
            # æ›´æ–°è¿›åº¦
            progress = int((i / total) * 100)
            progress_container["vision"]["progress"] = progress
            progress_container["vision"]["message"] = f"Qwen3-VLåˆ†æä¸­: {os.path.basename(pdf_file)}"

            # è¿™é‡Œå¯ä»¥æ·»åŠ é¢å¤–çš„è§†è§‰åˆ†æ
            # ç›®å‰åŒé€šé“è§£æå™¨å·²ç»åŒ…å«äº†è§†è§‰åˆ†æ
            vision_results.append({
                "pdf_file": pdf_file,
                "status": "analyzed"
            })

        # å®Œæˆ
        progress_container["vision"]["progress"] = 100
        progress_container["vision"]["message"] = "è§†è§‰åˆ†æå®Œæˆ"

        return vision_results

    async def _generate_assembly_specification(
        self,
        pdf_results: List[Dict],
        vision_results: List[Dict],
        model_results: List[Dict],
        focus_type: str,
        special_requirements: str
    ) -> Dict:
        """ç”Ÿæˆè£…é…è§„ç¨‹"""

        self._log("ğŸ¤– DeepSeekå¼€å§‹åŒ¹é…BOMå’ŒGLBé›¶ä»¶...", "info")

        # æ•´ç†å€™é€‰äº‹å®
        all_candidate_facts = []
        bom_total = 0
        for pdf_result in pdf_results:
            facts = pdf_result.get("candidate_facts", {})
            all_candidate_facts.append(facts)
            bom_total += len(facts.get("bom_candidates", []))

        self._log(f"ğŸ“¦ BOMæ•°æ®: {bom_total}ä¸ªé›¶ä»¶", "info")

        # æ•´ç†æ¨¡å‹åˆ†æç»“æœ
        model_analysis = {
            "models": model_results,
            "total_models": len(model_results),
            "successful_conversions": sum(1 for r in model_results if r.get("glb_file"))
        }

        glb_parts = sum(r.get("part_count", 0) for r in model_results)
        self._log(f"ğŸ¨ GLBæ•°æ®: {glb_parts}ä¸ªé›¶ä»¶", "info")

        self._log(f"ğŸ”— å¼€å§‹åŒ¹é…: BOM({bom_total}é¡¹) â†” GLB({glb_parts}ä¸ªé›¶ä»¶)", "info")

        # è°ƒç”¨è£…é…ä¸“å®¶æ¨¡å‹
        self._log("ğŸ¤– è°ƒç”¨DeepSeekä¸“å®¶æ¨¡å‹è¿›è¡Œæ™ºèƒ½åŒ¹é…...", "info")

        result = self.assembly_expert.generate_assembly_specification(
            vision_analysis_results=all_candidate_facts,
            model_analysis_results=model_analysis,
            focus_type=focus_type,
            special_requirements=special_requirements
        )

        # âœ… æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°DeepSeekå®Œæ•´è¿”å›ç»“æ„
        print("\n" + "="*80)
        print("[DEBUG] DeepSeekå®Œæ•´è¿”å›ç»“æ„:")
        import json
        print(json.dumps(result, indent=2, ensure_ascii=False))
        print("="*80 + "\n")

        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if not result or not result.get("success"):
            error_msg = result.get("error", "æœªçŸ¥é”™è¯¯") if result else "æœªè¿”å›ç»“æœ"
            self._log(f"âŒ DeepSeekåŒ¹é…å¤±è´¥: {error_msg}", "error")
            raise Exception(f"DeepSeekåŒ¹é…å¤±è´¥: {error_msg}")

        # æå–ç»“æœæ•°æ®
        parsed_result = result.get("result", {})

        # âœ… æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°parsed_resultçš„ç±»å‹å’Œé”®
        print(f"[DEBUG] parsed_resultç±»å‹: {type(parsed_result)}")
        if isinstance(parsed_result, dict):
            print(f"[DEBUG] parsed_resulté”®: {list(parsed_result.keys())}")
        else:
            print(f"[DEBUG] parsed_resultä¸æ˜¯å­—å…¸: {parsed_result}")

        if not isinstance(parsed_result, dict):
            raise Exception("DeepSeekè¿”å›ç»“æœä¸æ˜¯æœ‰æ•ˆçš„JSONå¯¹è±¡")

        def resolve_list(source: Dict[str, Any], candidate_keys: List[str]) -> List[Any]:
            for key in candidate_keys:
                value = source.get(key)
                if isinstance(value, list):
                    return value
                if isinstance(value, dict):
                    nested = value.get('steps') or value.get('items') or value.get('data')
                    if isinstance(nested, list):
                        return nested
            return []

        def collect_parts_from_entry(entry):
            if entry is None:
                return
            if isinstance(entry, str):
                name = entry.strip()
                if name:
                    unique_parts.add(name)
                return
            if isinstance(entry, list):
                for item in entry:
                    collect_parts_from_entry(item)
                return
            if isinstance(entry, dict):
                for key in ('part_code', 'code', 'bom_code', 'name'):
                    value = entry.get(key)
                    if isinstance(value, str):
                        value = value.strip()
                        if value:
                            unique_parts.add(value)
                bom_ref = entry.get('bom_reference')
                if isinstance(bom_ref, dict):
                    collect_parts_from_entry(bom_ref.get('code'))
                    collect_parts_from_entry(bom_ref.get('name'))
                for nested_key in ('parts', 'parts_involved', 'components'):
                    nested = entry.get(nested_key)
                    if isinstance(nested, list):
                        collect_parts_from_entry(nested)
                return

        assembly_steps = resolve_list(parsed_result, ['assembly_steps', 'assembly_sequence', 'process_steps'])
        part_guides = resolve_list(parsed_result, ['part_assembly_guide', 'part_guides'])
        bom_mapping = parsed_result.get('bom_mapping') if isinstance(parsed_result.get('bom_mapping'), list) else []

        unique_parts = set()
        collect_parts_from_entry(assembly_steps)
        collect_parts_from_entry(part_guides)
        collect_parts_from_entry(parsed_result.get('parts'))
        collect_parts_from_entry(parsed_result.get('components'))
        collect_parts_from_entry(parsed_result.get('critical_connections'))
        collect_parts_from_entry(bom_mapping)

        matched_from_mapping = len([m for m in bom_mapping if isinstance(m, dict) and m.get('matched')]) if bom_mapping else 0
        matched_count = matched_from_mapping or len(unique_parts)
        if matched_count == 0:
            matched_count = len(unique_parts)

        bom_summary = parsed_result.get('bom_summary') if isinstance(parsed_result.get('bom_summary'), dict) else {}
        total_parts_reported = bom_summary.get('total_parts')
        try:
            total_parts_reported = int(total_parts_reported)
        except (ValueError, TypeError):
            total_parts_reported = None

        total_parts = total_parts_reported or bom_total or matched_count
        match_rate = (matched_count / total_parts * 100) if total_parts else 0.0

        statistics = {
            'bom_total': bom_total,
            'total_parts': total_parts,
            'matched_parts': matched_count,
            'match_rate': round(match_rate, 2),
            'assembly_step_count': len(assembly_steps),
            'part_guide_count': len(part_guides)
        }
        result['statistics'] = statistics

        rate_text = f"{match_rate:.1f}% ({matched_count}/{total_parts})" if total_parts else 'æš‚æ— æ€»æ•°'
        self._log(
            f"âœ… DeepSeekåŒ¹é…å®Œæˆ: è¦†ç›–{matched_count}ä¸ªé›¶ä»¶, {len(assembly_steps)}ä¸ªè£…é…æ­¥éª¤, åŒ¹é…ç‡{rate_text}",
            'success'
        )

        print(f"[DEBUG] ç»Ÿè®¡ä¿¡æ¯: {statistics}")

        return result

    async def _generate_html_manual(
        self,
        assembly_spec: Dict,
        model_results: List[Dict],
        output_dir: Path
    ) -> Dict:
        """ç”ŸæˆHTMLè£…é…è¯´æ˜ä¹¦"""
        from generators.html_generator import HTMLManualGenerator

        generator = HTMLManualGenerator()

        # å‡†å¤‡GLBæ–‡ä»¶åˆ—è¡¨
        glb_files = [
            r["glb_filename"] for r in model_results
            if r.get("glb_file") and os.path.exists(r["glb_file"])
        ]

        return generator.generate_manual(
            assembly_spec=assembly_spec,
            glb_files=glb_files,
            output_dir=str(output_dir)
        )

